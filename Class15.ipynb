{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyu1FTgqZcNcdhEvT1iV/g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/NeuralNetworksAndDeepLearning/blob/main/Class15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Networks for Recurrent Neural Networks**\n",
        "Recurrent Neural Networks (RNNs) are a fundamental class of neural networks designed to process sequential data with temporal dependencies, making them especially effective for tasks such as time series analysis, natural language processing, and speech recognition. Inspired by biological memory mechanisms, RNNs maintain internal states that allow past information to influence future predictions, enabling contextual understanding of sequences. Over time, several RNN architectures—such as traditional RNNs, LSTMs, GRUs, and bidirectional networks—have been developed to address challenges like gradient fading and training inefficiency. Despite limitations related to computational cost and sensitivity to hyperparameters, RNNs remain widely used in industry for applications ranging from financial forecasting to predictive maintenance, solidifying their importance in modern Deep Learning."
      ],
      "metadata": {
        "id": "9Q0oG44zSjxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example with Python: RNN with Keras**\n",
        "The following example demonstrates how an RNN can be built for sequence prediction using TensorFlow/Keras:"
      ],
      "metadata": {
        "id": "K8Cfb7ElPi2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "k_ggNb9q9He4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGGIgU2NShaJ",
        "outputId": "d698d9f5-1865-4bb4-ae5f-b288dbcb9776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "Predicted value: 2.728249\n"
          ]
        }
      ],
      "source": [
        "# Example sequential data; with samples, time steps and features:\n",
        "X = np.array([\n",
        "    [[1], [2], [3]],\n",
        "    [[2], [3], [4]],\n",
        "    [[3], [4], [5]]\n",
        "])\n",
        "y = np.array([4, 5, 6]  # Target values\n",
        "\n",
        "# Building the RNN model:\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(16, activation='tanh', input_shape=(3, 1)))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compiling the model:\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Training the model:\n",
        "model.fit(X, y, epochs=50, verbose=0)\n",
        "\n",
        "# Making a prediction:\n",
        "prediction = model.predict(np.array([[[4], [5], [6]]]))\n",
        "print('Predicted value:', prediction[0][0])"
      ]
    }
  ]
}